setwd("~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2")
res = read.csv('models_final_dl/james_loss_summ.csv')
library(RColorBrewer)
cols = brewer.pal(n = 4, name = 'Spectral')
frac_fits = as.character(c(1,0.9,0.8,0.6,0.4))
losses = c('mse','min','avg')
## Just going to plot with gamma == 0.99
gammas = as.character(c(99))#as.character(c(90,95,99))
models = c('dl_l','rf','ridge','svr')
model_names=c('Deep Learning','Random Forests','Ridge Regression','Support Vector Machines')
names(cols) = models
ys = array(dim = length(frac_fits))
names(ys) = frac_fits
up_ys = c(12); names(up_ys)=gammas
line_types = c(2,4)
par(mfrow=c(1,2),bty='n',las=1)
for(g in gammas){
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,up_ys[g]), main=paste('Active-rank on top ',g, '%'),
xlab='% of ranked training activity data',ylab='Total model score',xaxt='n')
axis(1,at=frac_fits, labels = 100*as.numeric(frac_fits))
for (m in models){
c = 1
for(l in losses){
if(l != 'mse'){
for(f in frac_fits){
ind = intersect(intersect(grep(l, res$losses), grep(g, res$losses)), grep(f, res$losses))
ys[f] = res[ind,m]
}
lines(frac_fits, ys, lty=line_types[c], col=cols[m],lwd=3)
c = c+1
}
}
#}
}
}
l='mse'
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,25), main='Mean Squared Error',
xlab='% of ranked activity data used',ylab='Total model score',xaxt='n')
axis(1,at=frac_fits, labels = 100*as.numeric(frac_fits))
for (m in models){
for(f in frac_fits){
ind = intersect(grep(l, res$losses), grep(f, res$losses))
ys[f] = res[ind,m]
}
lines((frac_fits), ys, lty=1, col=cols[m],lwd=3)
}
pdf('figures_dl/Overall_Results.pdf')
par(mfrow=c(1,2),bty='n',las=1)
for(g in gammas){
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,up_ys[g]), main=paste('Active-rank on top ',g, '%'),
xlab='% of ranked training activity data',ylab='Total model score',xaxt='n')
axis(1,at=frac_fits, labels = 100*as.numeric(frac_fits))
for (m in models){
c = 1
for(l in losses){
if(l != 'mse'){
for(f in frac_fits){
ind = intersect(intersect(grep(l, res$losses), grep(g, res$losses)), grep(f, res$losses))
ys[f] = res[ind,m]
}
lines(frac_fits, ys, lty=line_types[c], col=cols[m],lwd=3)
c = c+1
}
}
#}
}
}
l='mse'
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,25), main='Mean Squared Error',
xlab='% of ranked activity data used',ylab='Total model score',xaxt='n')
axis(1,at=frac_fits, labels = 100*as.numeric(frac_fits))
for (m in models){
for(f in frac_fits){
ind = intersect(grep(l, res$losses), grep(f, res$losses))
ys[f] = res[ind,m]
}
lines((frac_fits), ys, lty=1, col=cols[m],lwd=3)
}
dev.off()
#legend('topright',col=cols,legend = model_names,lwd=3,
#       cex=1,bty='n')
source('~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2/plot_results_all.R', echo=TRUE)
source('~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2/plot_results_all.R', echo=TRUE)
source('~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2/plot_results_all.R', echo=TRUE)
source('~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2/plot_results_all.R', echo=TRUE)
source('~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2/plot_results_all.R', echo=TRUE)
source('~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2/plot_results_all.R', echo=TRUE)
library(RColorBrewer)
cols = brewer.pal(n = 4, name = 'Spectral')
frac_fits = as.character(c(1,0.9,0.8,0.6,0.4))
losses = c('mse','min','avg')
## Just going to plot with gamma == 0.99
gammas = as.character(c(90,95,99))
models = c('dl_l','rf','ridge','svr')
model_names=c('Deep Learning','Random Forests','Ridge Regression','Support Vector Machines')
names(cols) = models
ys = array(dim = length(frac_fits))
names(ys) = frac_fits
up_ys = c(12,25,25); names(up_ys)=gammas
line_types = c(2,4)
par(mfrow=c(2,2),bty='n',las=1)
for(g in gammas){
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,up_ys[g]), main=paste('Active-rank on top ',g, '%'),
xlab='% of ranked training activity data',ylab='Total model score',xaxt='n')
axis(1,at=frac_fits, labels = 100*as.numeric(frac_fits))
for (m in models){
c = 1
for(l in losses){
if(l != 'mse'){
for(f in frac_fits){
ind = intersect(intersect(grep(l, res$losses), grep(g, res$losses)), grep(f, res$losses))
ys[f] = res[ind,m]
}
lines(frac_fits, ys, lty=line_types[c], col=cols[m],lwd=3)
c = c+1
}
}
#}
}
}
l='mse'
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,25), main='Mean Squared Error',
xlab='% of ranked activity data used',ylab='Total model score',xaxt='n')
axis(1,at=frac_fits, labels = 100*as.numeric(frac_fits))
up_ys = c(25,25,12); names(up_ys)=gammas
par(mfrow=c(2,2),bty='n',las=1)
for(g in gammas){
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,up_ys[g]), main=paste('Active-rank on top ',g, '%'),
xlab='% of ranked training activity data',ylab='Total model score',xaxt='n')
axis(1,at=frac_fits, labels = 100*as.numeric(frac_fits))
for (m in models){
c = 1
for(l in losses){
if(l != 'mse'){
for(f in frac_fits){
ind = intersect(intersect(grep(l, res$losses), grep(g, res$losses)), grep(f, res$losses))
ys[f] = res[ind,m]
}
lines(frac_fits, ys, lty=line_types[c], col=cols[m],lwd=3)
c = c+1
}
}
#}
}
}
up_ys = c(15,25,12); names(up_ys)=gammas
line_types = c(2,4)
par(mfrow=c(2,2),bty='n',las=1)
for(g in gammas){
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,up_ys[g]), main=paste('Active-rank on top ',g, '%'),
xlab='% of ranked training activity data',ylab='Total model score',xaxt='n')
axis(1,at=frac_fits, labels = 100*as.numeric(frac_fits))
for (m in models){
c = 1
for(l in losses){
if(l != 'mse'){
for(f in frac_fits){
ind = intersect(intersect(grep(l, res$losses), grep(g, res$losses)), grep(f, res$losses))
ys[f] = res[ind,m]
}
lines(frac_fits, ys, lty=line_types[c], col=cols[m],lwd=3)
c = c+1
}
}
#}
}
}
l='mse'
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,25), main='Mean Squared Error',
xlab='% of ranked activity data used',ylab='Total model score',xaxt='n')
axis(1,at=frac_fits, labels = 100*as.numeric(frac_fits))
for (m in models){
for(f in frac_fits){
ind = intersect(grep(l, res$losses), grep(f, res$losses))
ys[f] = res[ind,m]
}
lines((frac_fits), ys, lty=1, col=cols[m],lwd=3)
}
source('~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2/plot_results_all.R', echo=TRUE)
source('~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2/plot_results_all.R', echo=TRUE)
dev.off()
res = read.csv('models_final_dl/james_loss_summ.csv')
library(RColorBrewer)
cols = brewer.pal(n = 4, name = 'Spectral')
frac_fits = as.character(c(1,0.9,0.8,0.6,0.4))
losses = c('mse','min','avg')
## Just going to plot with gamma == 0.99
gammas = as.character(c(90,95,99))
models = c('dl_l','rf','ridge','svr')
model_names=c('Deep Learning','Random Forests','Ridge Regression','Support Vector Machines')
names(cols) = models
ys = array(dim = length(frac_fits))
names(ys) = frac_fits
up_ys = c(15,25,12); names(up_ys)=gammas
line_types = c(2,4)
pdf('figures_dl/Overall_Results.pdf')
par(mfrow=c(2,2),bty='n',las=1)
for(g in gammas){
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,up_ys[g]), main=paste('Active-rank on top ',g, '%'),
xlab='% of ranked training activity data',ylab='Total model score',xaxt='n')
axis(1,at=c(0.4,.6,.8,1), labels = 100*c(0.4,.6,.8,1))
for (m in models){
c = 1
for(l in losses){
if(l != 'mse'){
for(f in frac_fits){
ind = intersect(intersect(grep(l, res$losses), grep(g, res$losses)), grep(f, res$losses))
ys[f] = res[ind,m]
}
lines(frac_fits, ys, lty=line_types[c], col=cols[m],lwd=3)
c = c+1
}
}
#}
}
}
l='mse'
plot(NA,NA,xlim=c(0.4,1), ylim=c(0,25), main='Mean Squared Error',
xlab='% of ranked activity data used',ylab='Total model score',xaxt='n')
axis(1,at=c(0.4,.6,.8,1), labels = 100*c(0.4,.6,.8,1))
for (m in models){
for(f in frac_fits){
ind = intersect(grep(l, res$losses), grep(f, res$losses))
ys[f] = res[ind,m]
}
lines((frac_fits), ys, lty=1, col=cols[m],lwd=3)
}
dev.off()
#legend('topright',col=cols,legend = model_names,lwd=3,
#       cex=1,bty='n')
source('~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2/plot_results_all.R', echo=TRUE)
source('~/Dropbox/Statistical Methodology/ComputationalChemistry/paper2/plot_results_all.R', echo=TRUE)
